[["index.html", "Data preparation for Harvard Talk 1 Project Information", " Data preparation for Harvard Talk Tim Disher 2021-05-18 1 Project Information Generation of materials for Harvard neo talk. This analysis was developed using a package structure, with the analysis organized as a series of functions. If you are just joining this project please start here to understand the over-arching goal of the analysis. The functions are built to work as a stand-alone workflow, and can be run in the correct order by calling the bookdown::serve_book() function with the index.Rmd file open. This project makes use of caching for long-running analyses but the cache is not tracked on git. The first run can be expected to take a reasonably long amount of time after which subsequent renders are usually &lt; 1 minute. "],["generate-pseudo-data.html", "2 Generate Pseudo Data 2.1 Generate data from synthpop", " 2 Generate Pseudo Data In the final section of this presentation we will walk through a proposal that pretty much all trial data can and should be turned into portable pseudo data that is shared freely without restrictions. We has originally planned to show two versions of this: one using {synthpop} and the other using {mvProbit}. After reviewing the synthpop documentation more closely however it looks like you can actually just save the model objects which means you can interact with them using local data. This is much faster/more general than the multivariate probit approach so we won’t move that work forward any further. Note that this repository also includes the code necessary to do a bayesian version of the multivariate probit model which is primarily of interest if you’d like to do something like specify treatment effects across binomial outcomes as shared/exchangeable. 2.1 Generate data from synthpop We will use vanilla default settings for synthpop since the data here is simulated but in real applications there is a lot more fine tuning available. We can get a nice simple default output compare synthetic to original data using the compare function. data(&quot;ex_dat&quot;) dat &lt;- as.data.frame(ex_dat) %&gt;% dplyr::select(trt, mort, sev_ivh, sepsis, cld, nec) set.seed(124) synth_dat &lt;- xfun::cache_rds({ syn(dat, minnumlevels = 5, m = 10, models = FALSE, method = &quot;parametric&quot;) }, dir = cache, file = &quot;synth_dat.rds&quot;) compare(synth_dat, data = dat) ## ## Comparing percentages observed with synthetic ## ## $trt ## 0 1 ## observed 50.00000 50.00000 ## synthetic 50.13333 49.86667 ## ## $mort ## 0 1 ## observed 84.88889 15.11111 ## synthetic 85.05185 14.94815 ## ## $sev_ivh ## 0 1 ## observed 91.55556 8.444444 ## synthetic 91.54074 8.459259 ## ## $sepsis ## 0 1 ## observed 78.29630 21.70370 ## synthetic 77.97778 22.02222 ## Press return for next plot: $cld ## 0 1 ## observed 60.29630 39.70370 ## synthetic 59.91111 40.08889 ## ## $nec ## 0 1 ## observed 95.70370 4.296296 ## synthetic 95.22222 4.777778 We can also take a quick look at correlations for a pooled version of the synthetic datasets vs the observed data. synth_dat$syn %&gt;% do.call(rbind, .) %&gt;% mutate_all(as.numeric) %&gt;% select(-trt) %&gt;% cor() ## mort sev_ivh sepsis cld nec ## mort 1.0000000 0.10174852 0.11359478 -0.11996149 0.11452450 ## sev_ivh 0.1017485 1.00000000 0.08190459 -0.02053963 0.02425813 ## sepsis 0.1135948 0.08190459 1.00000000 0.10765597 0.01337243 ## cld -0.1199615 -0.02053963 0.10765597 1.00000000 0.05132358 ## nec 0.1145245 0.02425813 0.01337243 0.05132358 1.00000000 dat[,-1] %&gt;% cor() ## mort sev_ivh sepsis cld nec ## mort 1.0000000 0.11732436 0.11401142 -0.12256408 0.11459764 ## sev_ivh 0.1173244 1.00000000 0.10506595 -0.03409620 0.01448092 ## sepsis 0.1140114 0.10506595 1.00000000 0.09426759 0.01251141 ## cld -0.1225641 -0.03409620 0.09426759 1.00000000 0.05205256 ## nec 0.1145976 0.01448092 0.01251141 0.05205256 1.00000000 For the rest of the presentation we will just use on example dataset. For the comparison at the end we will create a composite with sev_ivh + cld pres_dat_syn &lt;- synth_dat$syn[[10]] %&gt;% mutate_all(~ as.numeric(as.character(.))) %&gt;% mutate(cld_ivh = ifelse(sev_ivh == 1 &amp; cld == 1, 1, 0), cld_no_ivh = ifelse(cld == 1 &amp; sev_ivh == 0, 1, 0), ivh_no_cld = ifelse(cld == 0 &amp; sev_ivh == 1, 1, 0)) pres_dat &lt;- dat %&gt;% mutate(cld_ivh = ifelse(sev_ivh == 1 &amp; cld == 1, 1, 0), cld_no_ivh = ifelse(cld == 1 &amp; sev_ivh == 0, 1, 0), ivh_no_cld = ifelse(cld == 0 &amp; sev_ivh == 1, 1, 0)) colMeans(pres_dat) ## trt mort sev_ivh sepsis cld nec cld_ivh cld_no_ivh ivh_no_cld ## 0.50000000 0.15111111 0.08444444 0.21703704 0.39703704 0.04296296 0.02888889 0.36814815 0.05555556 colMeans(pres_dat_syn) ## trt mort sev_ivh sepsis cld nec cld_ivh cld_no_ivh ivh_no_cld ## 0.51703704 0.15111111 0.08592593 0.21333333 0.38592593 0.04962963 0.03629630 0.34962963 0.04962963 Overall just taking even a single dataset we’ve done pretty good at replicating the original data. "],["all-analyses.html", "3 All analyses 3.1 Things we can do without access to IPD 3.2 Approaches that we need IPD for", " 3 All analyses 3.1 Things we can do without access to IPD 3.1.1 Adjusting p-value for decision at hand glms &lt;- cache_rds({lst( cld = glm(cld ~ trt, family = binomial, data = dat), mort = glm(mort ~ trt, family = binomial, data = dat) )}, dir = cache, file = &quot;marginal_glms&quot;) map(glms, summary) ## $cld ## ## Call: ## glm(formula = cld ~ trt, family = binomial, data = dat) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.0474 -1.0474 -0.9643 1.3132 1.4066 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.52428 0.07964 -6.583 4.61e-11 *** ## trt 0.21062 0.11142 1.890 0.0587 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1813.8 on 1349 degrees of freedom ## Residual deviance: 1810.3 on 1348 degrees of freedom ## AIC: 1814.3 ## ## Number of Fisher Scoring iterations: 4 ## ## ## $mort ## ## Call: ## glm(formula = mort ~ trt, family = binomial, data = dat) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.5994 -0.5994 -0.5445 -0.5445 1.9910 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.6255 0.1038 -15.655 &lt;2e-16 *** ## trt -0.2083 0.1525 -1.366 0.172 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1146.5 on 1349 degrees of freedom ## Residual deviance: 1144.6 on 1348 degrees of freedom ## AIC: 1148.6 ## ## Number of Fisher Scoring iterations: 4 conf_vector &lt;- seq(from = 0.95, to = 0.7, length.out = 10) power &lt;- FALSE i &lt;- 1 while(power == FALSE){ pwr &lt;- epiR::epi.sscc(OR = 0.7, # Coincides to risk difference of 8% based on 36% baseline risk p0 = 0.36, n = 1350, conf.level = conf_vector[[i]], power = NA) power = pwr$power &gt;= 0.9 i = i + 1 } new_alpha &lt;- 1 - conf_vector[[i]] Before we get into more direct decision theory approaches, one simple way we can make decisions a little more local is just by re-evaluating our values of alpha and beta. Let’s use CLD as a rough proxy for risk of disability and say that maybe locally we are willing to risk more false positives in order to decrease our possibility of missing a true effect. Instead of the default assumption that a false positive is four times worse than a false negative let’s say in this case we decide that the potential harm from this intervention is such that we’re willing to risk a two to one trade off. If we fix the sample size and assume we woudn’t want to miss a risk difference of 8% (OR of 0.7) then this would equate to a p-value of 0.11. This equates to a decision rule that “If I can be confident in the direction of the effect” using alpha/beta to weigh risks of false negative/positive then you act “as if” there is/is not a difference. 3.1.2 MCDA from marginals In the first step we will need marginal probabilities with uncertainty from each outcome we’d like to include in the mcda. An easy way to do this is just to run a glm and then sample predicted probabilities from the variance covariance matrix. outs &lt;- purrr::set_names(c(&quot;mort&quot;, &quot;sev_ivh&quot;, &quot;sepsis&quot;, &quot;cld&quot;, &quot;nec&quot;)) mcda_marg_dat &lt;- mcda_prep(outs, data = pres_dat) mcda_marg &lt;- cache_rds({ lst(dat = mcda_marg_dat, mcda = do_mcda(5, mcda_marg_dat)) }, dir = cache, file = &quot;marg_mcda&quot;) 3.2 Approaches that we need IPD for 3.2.1 Ordinal model An alternative approach might be to arrange outcomes from best to worse and then use an ordinal model to run the analysis interpreting the treatment effect as a kind of improvement in quasi utility. ord &lt;- c(&quot;sepsis&quot;, &quot;nec&quot;, &quot;cld&quot;, &quot;sev_ivh&quot;, &quot;mort&quot;) dat_ord_orig &lt;- make_ord(data = pres_dat, name = &quot;ord1&quot;, order = ord) dat_ord_synth &lt;- make_ord(data = pres_dat_syn, name = &quot;ord1&quot;, order = ord) ord_models &lt;- cache_rds({ lst( orig = rms::orm(ord1 ~ trt, data = dat_ord_orig), synth = rms::orm(ord1 ~ trt, data = dat_ord_synth) ) }, dir = cache, file = &quot;ord_models&quot;) ord_models ## $orig ## Logistic (Proportional Odds) Ordinal Regression Model ## ## rms::orm(formula = ord1 ~ trt, data = dat_ord_orig) ## ## ## Frequencies of Responses ## ## no_event sepsis nec cld sev_ivh mort ## 510 293 44 372 47 84 ## ## Model Likelihood Discrimination Rank Discrim. ## Ratio Test Indexes Indexes ## Obs 1350 LR chi2 0.42 R2 0.000 rho 0.018 ## Distinct Y 6 d.f. 1 g 0.032 ## Median Y 2 Pr(&gt; chi2) 0.5162 gr 1.033 ## max |deriv| 2e-06 Score chi2 0.42 |Pr(Y&gt;=median)-0.5| 0.123 ## Pr(&gt; chi2) 0.5162 ## ## Coef S.E. Wald Z Pr(&gt;|Z|) ## y&gt;=sepsis 0.4685 0.0732 6.40 &lt;0.0001 ## y&gt;=nec -0.4150 0.0733 -5.66 &lt;0.0001 ## y&gt;=cld -0.5525 0.0743 -7.44 &lt;0.0001 ## y&gt;=sev_ivh -2.2633 0.1050 -21.55 &lt;0.0001 ## y&gt;=mort -2.7455 0.1235 -22.22 &lt;0.0001 ## trt 0.0641 0.0987 0.65 0.5163 ## ## ## $synth ## Logistic (Proportional Odds) Ordinal Regression Model ## ## rms::orm(formula = ord1 ~ trt, data = dat_ord_synth) ## ## ## Frequencies of Responses ## ## no_event sepsis nec cld sev_ivh mort ## 508 288 51 359 47 97 ## ## Model Likelihood Discrimination Rank Discrim. ## Ratio Test Indexes Indexes ## Obs 1350 LR chi2 0.69 R2 0.001 rho 0.023 ## Distinct Y 6 d.f. 1 g 0.041 ## Median Y 2 Pr(&gt; chi2) 0.4053 gr 1.042 ## max |deriv| 4e-06 Score chi2 0.69 |Pr(Y&gt;=median)-0.5| 0.124 ## Pr(&gt; chi2) 0.4053 ## ## Coef S.E. Wald Z Pr(&gt;|Z|) ## y&gt;=sepsis 0.4645 0.0746 6.23 &lt;0.0001 ## y&gt;=nec -0.4041 0.0747 -5.41 &lt;0.0001 ## y&gt;=cld -0.5632 0.0757 -7.44 &lt;0.0001 ## y&gt;=sev_ivh -2.1686 0.1026 -21.14 &lt;0.0001 ## y&gt;=mort -2.6018 0.1177 -22.11 &lt;0.0001 ## trt 0.0820 0.0985 0.83 0.4053 ## 3.2.2 MCDA with conditional A drawback of the ordinal model is that it doesn’t let us specify how much worse one outcome is than another. We can extend the marginal MCDA to account for combinations of outcomes being worse by leveraging our synthetic dataset. This could be extended further by having non-linear partial utilities or other considerations. outs_prep &lt;- c(&quot;mort&quot;, &quot;sepsis&quot;, &quot;nec&quot;, &quot;cld_ivh&quot;) mcda_comb_list &lt;- cache_rds({ set.seed(124) mcda_comb_orig_dat &lt;- mcda_prep(outs_prep, data = pres_dat) mcda_comb_orig &lt;- do_mcda(4, mcda_comb_orig_dat) set.seed(124) mcda_comb_syn_dat &lt;- mcda_prep(outs_prep, data = pres_dat_syn) mcda_comb_syn &lt;- do_mcda(4, mcda_comb_syn_dat) lst(orig_dat = mcda_comb_orig_dat, orig_mcda = mcda_comb_orig, comb_dat = mcda_comb_syn_dat, comb_mcda = mcda_comb_syn) }, dir = cache, file = &quot;comb_mcdas&quot;) "]]
